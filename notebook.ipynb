{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Osmotic Learning Experiments\n",
    "\n",
    "This notebook implements and analyzes several experiments related to the **Osmotic Learning (OSM-L) paradigm**. \n",
    "OSM-L is a self-supervised learning method that enables distributed entities to learn contextual representations without explicit supervision. \n",
    "These experiments aim to validate the latent representation alignment, robustness to noise, and the emergence of dynamic sub-contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator.core.agent import Agent\n",
    "from simulator.core.diffuser import Diffuser\n",
    "from simulator.misc.utils import set_seed\n",
    "from simulator.misc.visualization import plot_training_loss, plot_accuracy, plot_embeddings_similarity_matrix\n",
    "\n",
    "from models.base import MODEL_REGISTRY\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets.DataProcessor import DataProcessor\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Latent Representation and Training Convergence\n",
    "\n",
    "In this experiment, we train two agents (Agent0 and Agent1) in a **simple context**, where both agents have correlated data. \n",
    "The objective is to evaluate whether **local embeddings converge to a shared representation** using OSM-L's diffusion mechanism.\n",
    "\n",
    "- **Key Hypothesis:** The embeddings of both agents should align, despite training occurring independently.\n",
    "- **Metric:** Similarity matrix of embeddings over time.\n",
    "- **Expected Outcome:** If OSM-L works correctly, embeddings generated by Agent0 and Agent1 at the same logical step should be highly similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the experiment\n",
    "\n",
    "WINDOW_SIZE = 10\n",
    "TRAIN_DATA_CSV = 'datasets/simple-context/train_data.csv'\n",
    "TEST_DATA_CSV = 'datasets/simple-context/test_data.csv'\n",
    "EPOCHS = 5\n",
    "EMBEDDING_SIZE = 5\n",
    "BATCH_SIZE = 50\n",
    "CLUSTERING_STEP = 2\n",
    "GRU_HIDDEN_DIM = 20\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the dataset\n",
    "The dataset is loaded from CSV files, and only the first two agents (0 and 1) are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcessor = DataProcessor(window_size=WINDOW_SIZE)\n",
    "data = dataProcessor.load_data_from_csv(TRAIN_DATA_CSV, TEST_DATA_CSV)\n",
    "\n",
    "# Maintain only first two Agents from Simple Context\n",
    "data = {\n",
    "    'train': {\n",
    "        0: data['train']['0'],\n",
    "        1: data['train']['1']\n",
    "    },\n",
    "    'test': {\n",
    "        0: data['test']['0'],\n",
    "        1: data['test']['1']\n",
    "    }\n",
    "}\n",
    "data = dataProcessor.load_data(data['train'], data['test'])\n",
    "agents_data = dataProcessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time series\n",
    "This visualization helps verify the structure and correlation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcessor.plot_time_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize agents and communication queues\n",
    "Each agent is assigned its own queue for sending and receiving messages and processes local data using a GRU-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS = len(agents_data['train'])\n",
    "sending_queues = {agent_id: mp.Queue() for agent_id in agents_data['train'].keys()}\n",
    "receiving_queues = {agent_id: mp.Queue() for agent_id in agents_data['train'].keys()}\n",
    "results_queue = mp.Queue()\n",
    "\n",
    "agents = {}\n",
    "for agent_id, data in agents_data['train'].items():\n",
    "    dataset = TensorDataset(data['series'])\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    dataset = TensorDataset(agents_data['test'][agent_id]['series'])\n",
    "    testloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    model = MODEL_REGISTRY[\"gru\"](\n",
    "        input_dim=data[\"features\"],\n",
    "        hidden_dim=GRU_HIDDEN_DIM,\n",
    "        output_dim=EMBEDDING_SIZE\n",
    "    )\n",
    "    agent = Agent(\n",
    "        agent_id=agent_id,\n",
    "        model=model,\n",
    "        train_loader=dataloader,\n",
    "        test_loader=testloader,\n",
    "        results_queue=results_queue,\n",
    "        sending_queue=sending_queues[agent_id],\n",
    "        receiving_queue=receiving_queues[agent_id],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    agents[agent_id] = agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Diffuser\n",
    "The **Diffuser** coordinates the learning process by aligning embeddings across agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser = Diffuser(\n",
    "    agents=agents,\n",
    "    epochs=EPOCHS,\n",
    "    clustering=True,\n",
    "    clustering_step=CLUSTERING_STEP,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training process\n",
    "This step allows **local embeddings to converge** while preserving individual data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_embeddings, metrics = diffuser.run(evaluate=True, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n",
    "The evaluation measures how well the learned embeddings generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_data = diffuser.evaluate(agents_data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the embeddings similarity matrix\n",
    "This matrix visualizes how well the embeddings from different agents align over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_similarity_matrix(evaluate_data, (6,4), tickevery=30, min=0.4, max=1, cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results for Experiment 1: Latent Representation and Training Convergence**\n",
    "\n",
    "The results confirm that **OSM-L successfully aligns local embeddings**, achieving a **0.9984 accuracy at epoch 4**. The similarity matrix shows that embeddings produced by Agent0 and Agent1 at the same logical step **converge to a shared representation**, despite independent training. Notably, in the interval [50, 100], the model correctly identifies a stationary phase, demonstrating its ability to **capture contextual consistency** even when local data exhibit oscillatory behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the agents\n",
    "After training and evaluation, the agents are stopped to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser.stop_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Robustness of Learning\n",
    " \n",
    "This experiment introduces **two misleading agents** (AgentM0 and AgentM1) with randomly generated data.\n",
    "The goal is to evaluate OSM-Lâ€™s **resilience against noise** and assess whether the diffusion process can **preserve alignment** among the correlated agents while ignoring uncorrelated ones.\n",
    "\n",
    "- **Key Hypothesis:** The embeddings of correlated agents (Agent0 and Agent1) should remain aligned, while misleading agents should not influence the global representation.\n",
    "- **Metric:** Similarity matrices of all four agents.\n",
    "- **Expected Outcome:** The embeddings of misleading agents should not exhibit structured similarity patterns, confirming that OSM-L **filters out irrelevant information**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload and preprocess the dataset\n",
    "The same dataset is reloaded, this time without filtering any agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcessor = DataProcessor(window_size=WINDOW_SIZE)\n",
    "data = dataProcessor.load_data_from_csv(TRAIN_DATA_CSV, TEST_DATA_CSV)\n",
    "data = dataProcessor.load_data(data['train'], data['test'])\n",
    "agents_data = dataProcessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time series for all agents\n",
    "This visualization now includes the misleading agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcessor.plot_time_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize agents and queues\n",
    "All four agents (including the misleading ones) are included in this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS = len(agents_data['train'])\n",
    "sending_queues = {agent_id: mp.Queue() for agent_id in agents_data['train'].keys()}\n",
    "receiving_queues = {agent_id: mp.Queue() for agent_id in agents_data['train'].keys()}\n",
    "results_queue = mp.Queue()\n",
    "\n",
    "agents = {}\n",
    "for agent_id, data in agents_data['train'].items():\n",
    "    dataset = TensorDataset(data['series'])\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    dataset = TensorDataset(agents_data['test'][agent_id]['series'])\n",
    "    testloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    model = MODEL_REGISTRY[\"gru\"](\n",
    "        input_dim=data[\"features\"],\n",
    "        hidden_dim=GRU_HIDDEN_DIM,\n",
    "        output_dim=EMBEDDING_SIZE\n",
    "    )\n",
    "    agent = Agent(\n",
    "        agent_id=agent_id,\n",
    "        model=model,\n",
    "        train_loader=dataloader,\n",
    "        test_loader=testloader,\n",
    "        results_queue=results_queue,\n",
    "        sending_queue=sending_queues[agent_id],\n",
    "        receiving_queue=receiving_queues[agent_id],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    agents[agent_id] = agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Diffuser\n",
    "The **Diffuser** coordinates the learning process by aligning embeddings across agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser = Diffuser(\n",
    "    agents=agents,\n",
    "    epochs=EPOCHS,\n",
    "    clustering=True,\n",
    "    clustering_step=CLUSTERING_STEP,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training process\n",
    "This step allows **local embeddings to converge** while preserving individual data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_embeddings, metrics = diffuser.run(evaluate=True, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n",
    "The evaluation measures how well the learned embeddings generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_data = diffuser.evaluate(agents_data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the embeddings similarity matrix\n",
    "This matrix visualizes how well the embeddings from different agents align over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_similarity_matrix(evaluate_data, (6,4), tickevery=30, min=0.7, max=1, cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results for Experiment 2: Robustness of Learning**\n",
    "\n",
    "Even in the presence of misleading agents, OSM-L **preserves representation alignment** among the correlated agents (Agent0 and Agent1). The similarity matrix of these agents **retains its structured pattern**, whereas the misleading agents (AgentM0 and AgentM1) exhibit **randomized embeddings without a clear diagonal structure**. This confirms that **OSM-L effectively filters out uncorrelated information**, preventing the diffusion process from being influenced by noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the agents\n",
    "After training and evaluation, the agents are stopped to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser.stop_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Emergence of Sub-Contexts\n",
    "\n",
    "In this experiment, we transition from a simple to a **complex context**, adding three more agents (Agent2, Agent3, and Agent4).\n",
    "The objective is to analyze how **OSM-L dynamically forms sub-contexts** among correlated agents.\n",
    "\n",
    "- **Key Hypothesis:** OSM-L should **group agents into meaningful clusters** based on their correlation, without prior knowledge.\n",
    "- **Metric:** Evolution of similarity matrices over multiple epochs.\n",
    "- **Expected Outcome:** \n",
    "    - Agents sharing strong correlations (Agent0 and Agent1; Agent2 and Agent3) should **form stable sub-contexts**.\n",
    "    - Agent4, which has **partial correlations** with other agents, should eventually align within an appropriate cluster.\n",
    "\n",
    "The results will confirm whether OSM-L can **autonomously identify and adapt to latent structures in distributed data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the experiment\n",
    "\n",
    "WINDOW_SIZE = 10\n",
    "TRAIN_DATA_CSV = 'datasets/complex-context/train_data.csv'\n",
    "TEST_DATA_CSV = 'datasets/complex-context/test_data.csv'\n",
    "EPOCHS = 30\n",
    "EMBEDDING_SIZE = 5\n",
    "BATCH_SIZE = 50\n",
    "CLUSTERING_STEP = 2\n",
    "GRU_HIDDEN_DIM = 20\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the dataset\n",
    "The dataset is loaded from CSV files from the 'complex context', consisting of Agent0, Agent1, Agent2, Agent3, Agent4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcessor = DataProcessor(window_size=WINDOW_SIZE)\n",
    "data = dataProcessor.load_data_from_csv(TRAIN_DATA_CSV, TEST_DATA_CSV)\n",
    "data = dataProcessor.load_data(data['train'], data['test'])\n",
    "agents_data = dataProcessor.preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time series for all agents\n",
    "This visualization now includes four agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProcessor.plot_time_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize agents and communication queues\n",
    "Each agent is assigned its own queue for sending and receiving messages and processes local data using a GRU-based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AGENTS = len(agents_data['train'])\n",
    "sending_queues = {agent_id: mp.Queue() for agent_id in agents_data['train'].keys()}\n",
    "receiving_queues = {agent_id: mp.Queue() for agent_id in agents_data['train'].keys()}\n",
    "results_queue = mp.Queue()\n",
    "\n",
    "agents = {}\n",
    "for agent_id, data in agents_data['train'].items():\n",
    "    dataset = TensorDataset(data['series'])\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    dataset = TensorDataset(agents_data['test'][agent_id]['series'])\n",
    "    testloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    model = MODEL_REGISTRY[\"gru\"](\n",
    "        input_dim=data[\"features\"],\n",
    "        hidden_dim=GRU_HIDDEN_DIM,\n",
    "        output_dim=EMBEDDING_SIZE\n",
    "    )\n",
    "    agent = Agent(\n",
    "        agent_id=agent_id,\n",
    "        model=model,\n",
    "        train_loader=dataloader,\n",
    "        test_loader=testloader,\n",
    "        results_queue=results_queue,\n",
    "        sending_queue=sending_queues[agent_id],\n",
    "        receiving_queue=receiving_queues[agent_id],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    agents[agent_id] = agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Diffuser\n",
    "The **Diffuser** coordinates the learning process by aligning embeddings across agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser = Diffuser(\n",
    "    agents=agents,\n",
    "    epochs=EPOCHS,\n",
    "    clustering=True,\n",
    "    clustering_step=CLUSTERING_STEP,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training process\n",
    "This step allows **local embeddings to converge** while preserving individual data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_embeddings, metrics = diffuser.run(evaluate=True, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Training Loss and Accuracy over Epochs\n",
    "Plot training loss and accuracy showing their evolution during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = metrics[\"training_losses\"]\n",
    "plot_training_loss(training_losses)\n",
    "plot_accuracy(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n",
    "The evaluation measures how well the learned embeddings generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_data = diffuser.evaluate(agents_data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the embeddings similarity matrix\n",
    "This matrix visualizes how well the embeddings from different agents align over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_similarity_matrix(evaluate_data, (6,4), tickevery=30, min=0.7, max=1, cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results for Experiment 3: Emergence of Sub-Contexts**\n",
    "\n",
    "The similarity matrices reveal the **formation of distinct sub-contexts**, with **Agent0-Agent1** and **Agent2-Agent4** converging into separate clusters. Despite a negative correlation, Agent2 and Agent3 **align within the same sub-context**, while Agent4 dynamically integrates based on its **partial correlation**. The training loss **rapidly decreases**, and accuracy peaks at **0.9954 at epoch 23**, confirming that OSM-L **dynamically structures contextual representations**, distinguishing relevant relationships without explicit supervision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the agents\n",
    "After training and evaluation, the agents are stopped to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuser.stop_agents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
